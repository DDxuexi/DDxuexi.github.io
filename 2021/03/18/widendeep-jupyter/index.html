<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>WideNDeep-tf实现 | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="import warnings warnings.filterwarnings(&quot;ignore&quot;) import itertools import pandas as pd import numpy as np from tqdm import tqdm from collections import namedtuple  import tensorflow as tf from tensorf">
<meta property="og:type" content="article">
<meta property="og:title" content="WideNDeep-tf实现">
<meta property="og:url" content="http://ddxuexi.github.io/2021/03/18/widendeep-jupyter/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="import warnings warnings.filterwarnings(&quot;ignore&quot;) import itertools import pandas as pd import numpy as np from tqdm import tqdm from collections import namedtuple  import tensorflow as tf from tensorf">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2021-03-18T08:43:20.095Z">
<meta property="article:modified_time" content="2021-03-19T03:33:42.361Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://ddxuexi.github.io/2021/03/18/widendeep-jupyter/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-03-19 11:33:42'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Hexo</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">WideNDeep-tf实现</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-03-18T08:43:20.095Z" title="发表于 2021-03-18 16:43:20">2021-03-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-03-19T03:33:42.361Z" title="更新于 2021-03-19 11:33:42">2021-03-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="WideNDeep-tf实现"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> itertools
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> collections <span class="token keyword">import</span> namedtuple

<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span>  MinMaxScaler<span class="token punctuation">,</span> LabelEncoder

<span class="token keyword">from</span> utils <span class="token keyword">import</span> SparseFeat<span class="token punctuation">,</span> DenseFeat<span class="token punctuation">,</span> VarLenSparseFeat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="模型部分"><a href="#模型部分" class="headerlink" title="模型部分"></a>模型部分</h3><ol>
<li>wide部分<ul>
<li><p>wide部分的输入包括数值型特征的输入和类别型特征的输入.数值型特征的输入后,经过concat-&gt;dense</p>
</li>
<li><p>concat将各个数值型特征的tensor拼接起来,经过Dense后相当于做了加和,Dense的过程中出现的参数体现了不同数值型特征的权重</p>
</li>
<li><p>如果直接对数值特征进行add()就忽视了不同特征之间的权重</p>
</li>
<li><p>类别型特征在Embedding后,相当于给其分配了不同的权重,所以可以直接add</p>
</li>
<li><p>wide部分输入的特征,应该是对结果相关性较为密切的特征,这样由于线性的记忆能力,可以使得线性部分的特征输入能有一个比较好的结果</p>
</li>
</ul>
</li>
<li>deep部分</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 读取数据</span>
data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/criteo_sample.txt'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>...</th>
      <th>C17</th>
      <th>C18</th>
      <th>C19</th>
      <th>C20</th>
      <th>C21</th>
      <th>C22</th>
      <th>C23</th>
      <th>C24</th>
      <th>C25</th>
      <th>C26</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>NaN</td>
      <td>3</td>
      <td>260.0</td>
      <td>NaN</td>
      <td>17668.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>33.0</td>
      <td>NaN</td>
      <td>...</td>
      <td>e5ba7672</td>
      <td>87c6f83c</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0429f84b</td>
      <td>NaN</td>
      <td>3a171ecb</td>
      <td>c0d61a5c</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>NaN</td>
      <td>-1</td>
      <td>19.0</td>
      <td>35.0</td>
      <td>30251.0</td>
      <td>247.0</td>
      <td>1.0</td>
      <td>35.0</td>
      <td>160.0</td>
      <td>...</td>
      <td>d4bb7bd8</td>
      <td>6fc84bfb</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5155d8a3</td>
      <td>NaN</td>
      <td>be7c41b4</td>
      <td>ded4aac9</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>2.0</td>
      <td>12.0</td>
      <td>2013.0</td>
      <td>164.0</td>
      <td>6.0</td>
      <td>35.0</td>
      <td>523.0</td>
      <td>...</td>
      <td>e5ba7672</td>
      <td>675c9258</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2e01979f</td>
      <td>NaN</td>
      <td>bcdee96c</td>
      <td>6d5d1302</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>NaN</td>
      <td>13</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>16836.0</td>
      <td>200.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>29.0</td>
      <td>...</td>
      <td>e5ba7672</td>
      <td>52e44668</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>e587c466</td>
      <td>NaN</td>
      <td>32c7478e</td>
      <td>3b183c5c</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>104.0</td>
      <td>27.0</td>
      <td>1990.0</td>
      <td>142.0</td>
      <td>4.0</td>
      <td>32.0</td>
      <td>37.0</td>
      <td>...</td>
      <td>e5ba7672</td>
      <td>25c88e42</td>
      <td>21ddcdc9</td>
      <td>b1252a9d</td>
      <td>0e8585d2</td>
      <td>NaN</td>
      <td>32c7478e</td>
      <td>0d4a6d1a</td>
      <td>001f3601</td>
      <td>92c878de</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 40 columns</p>
</div>




<pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 200 entries, 0 to 199
Data columns (total 40 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   label   200 non-null    int64  
 1   I1      110 non-null    float64
 2   I2      200 non-null    int64  
 3   I3      166 non-null    float64
 4   I4      165 non-null    float64
 5   I5      194 non-null    float64
 6   I6      149 non-null    float64
 7   I7      190 non-null    float64
 8   I8      200 non-null    float64
 9   I9      190 non-null    float64
 10  I10     110 non-null    float64
 11  I11     190 non-null    float64
 12  I12     43 non-null     float64
 13  I13     165 non-null    float64
 14  C1      200 non-null    object 
 15  C2      200 non-null    object 
 16  C3      191 non-null    object 
 17  C4      191 non-null    object 
 18  C5      200 non-null    object 
 19  C6      168 non-null    object 
 20  C7      200 non-null    object 
 21  C8      200 non-null    object 
 22  C9      200 non-null    object 
 23  C10     200 non-null    object 
 24  C11     200 non-null    object 
 25  C12     191 non-null    object 
 26  C13     200 non-null    object 
 27  C14     200 non-null    object 
 28  C15     200 non-null    object 
 29  C16     191 non-null    object 
 30  C17     200 non-null    object 
 31  C18     200 non-null    object 
 32  C19     118 non-null    object 
 33  C20     118 non-null    object 
 34  C21     191 non-null    object 
 35  C22     41 non-null     object 
 36  C23     200 non-null    object 
 37  C24     191 non-null    object 
 38  C25     118 non-null    object 
 39  C26     118 non-null    object 
dtypes: float64(12), int64(2), object(26)
memory usage: 62.6+ KB
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 将数据划分为sparse_feature和dense_feature</span>
columns <span class="token operator">=</span> data<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>values
columns<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>




<pre><code>array([&#39;label&#39;, &#39;I1&#39;, &#39;I2&#39;, &#39;I3&#39;, &#39;I4&#39;, &#39;I5&#39;, &#39;I6&#39;, &#39;I7&#39;, &#39;I8&#39;, &#39;I9&#39;,
       &#39;I10&#39;, &#39;I11&#39;, &#39;I12&#39;, &#39;I13&#39;, &#39;C1&#39;, &#39;C2&#39;, &#39;C3&#39;, &#39;C4&#39;, &#39;C5&#39;, &#39;C6&#39;,
       &#39;C7&#39;, &#39;C8&#39;, &#39;C9&#39;, &#39;C10&#39;, &#39;C11&#39;, &#39;C12&#39;, &#39;C13&#39;, &#39;C14&#39;, &#39;C15&#39;, &#39;C16&#39;,
       &#39;C17&#39;, &#39;C18&#39;, &#39;C19&#39;, &#39;C20&#39;, &#39;C21&#39;, &#39;C22&#39;, &#39;C23&#39;, &#39;C24&#39;, &#39;C25&#39;,
       &#39;C26&#39;], dtype=object)
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dense_features <span class="token operator">=</span> <span class="token punctuation">[</span> feat <span class="token keyword">for</span> feat <span class="token keyword">in</span> columns <span class="token keyword">if</span> <span class="token string">'I'</span> <span class="token keyword">in</span> feat<span class="token punctuation">]</span>
sparse_features <span class="token operator">=</span> <span class="token punctuation">[</span>feat <span class="token keyword">for</span> feat <span class="token keyword">in</span> columns <span class="token keyword">if</span> <span class="token string">'C'</span> <span class="token keyword">in</span> feat<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">dense_features<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>[&#39;I1&#39;,
 &#39;I2&#39;,
 &#39;I3&#39;,
 &#39;I4&#39;,
 &#39;I5&#39;,
 &#39;I6&#39;,
 &#39;I7&#39;,
 &#39;I8&#39;,
 &#39;I9&#39;,
 &#39;I10&#39;,
 &#39;I11&#39;,
 &#39;I12&#39;,
 &#39;I13&#39;]
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 数据处理的函数</span>
<span class="token keyword">def</span> <span class="token function">data_process</span><span class="token punctuation">(</span>data_df<span class="token punctuation">,</span>dense_features<span class="token punctuation">,</span>sparse_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    简单处理特征，包括填充缺失值，数值处理，类别编码
    param data_df: DataFrame格式的数据
    param dense_features: 数值特征名称列表
    param sparse_features: 类别特征名称列表
    """</span>
    data_df<span class="token punctuation">[</span>dense_features<span class="token punctuation">]</span> <span class="token operator">=</span> data_df<span class="token punctuation">[</span>dense_features<span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> f <span class="token keyword">in</span> dense_features<span class="token punctuation">:</span> <span class="token comment"># 对数值型特征的处理</span>
        data_df<span class="token punctuation">[</span>f<span class="token punctuation">]</span> <span class="token operator">=</span> data_df<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>x<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">if</span> x <span class="token operator">></span> <span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># 将类别型特征的空值填上-1    </span>
    data_df<span class="token punctuation">[</span>sparse_features<span class="token punctuation">]</span> <span class="token operator">=</span> data_df<span class="token punctuation">[</span>sparse_features<span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">"-1"</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> f <span class="token keyword">in</span> sparse_features<span class="token punctuation">:</span>
        lbe <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 对类别型特征进行了one-hot</span>
        data_df<span class="token punctuation">[</span>f<span class="token punctuation">]</span> <span class="token operator">=</span> lbe<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_df<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 传入的是个列表</span>
    
    <span class="token keyword">return</span> data_df<span class="token punctuation">[</span>dense_features <span class="token operator">+</span> sparse_features<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data <span class="token operator">=</span> data_process<span class="token punctuation">(</span>data<span class="token punctuation">,</span> dense_features<span class="token punctuation">,</span> sparse_features<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>I10</th>
      <th>...</th>
      <th>C17</th>
      <th>C18</th>
      <th>C19</th>
      <th>C20</th>
      <th>C21</th>
      <th>C22</th>
      <th>C23</th>
      <th>C24</th>
      <th>C25</th>
      <th>C26</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>1.386294</td>
      <td>5.564520</td>
      <td>0.000000</td>
      <td>9.779567</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>3.526361</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>8</td>
      <td>66</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>96</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000000</td>
      <td>-1.000000</td>
      <td>2.995732</td>
      <td>3.583519</td>
      <td>10.317318</td>
      <td>5.513429</td>
      <td>0.693147</td>
      <td>3.583519</td>
      <td>5.081404</td>
      <td>0.000000</td>
      <td>...</td>
      <td>7</td>
      <td>52</td>
      <td>0</td>
      <td>0</td>
      <td>47</td>
      <td>0</td>
      <td>7</td>
      <td>112</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.098612</td>
      <td>2.564949</td>
      <td>7.607878</td>
      <td>5.105945</td>
      <td>1.945910</td>
      <td>3.583519</td>
      <td>6.261492</td>
      <td>0.000000</td>
      <td>...</td>
      <td>8</td>
      <td>49</td>
      <td>0</td>
      <td>0</td>
      <td>25</td>
      <td>0</td>
      <td>6</td>
      <td>53</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000000</td>
      <td>2.639057</td>
      <td>0.693147</td>
      <td>1.609438</td>
      <td>9.731334</td>
      <td>5.303305</td>
      <td>1.791759</td>
      <td>1.609438</td>
      <td>3.401197</td>
      <td>0.000000</td>
      <td>...</td>
      <td>8</td>
      <td>37</td>
      <td>0</td>
      <td>0</td>
      <td>156</td>
      <td>0</td>
      <td>0</td>
      <td>32</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.653960</td>
      <td>3.332205</td>
      <td>7.596392</td>
      <td>4.962845</td>
      <td>1.609438</td>
      <td>3.496508</td>
      <td>3.637586</td>
      <td>0.000000</td>
      <td>...</td>
      <td>8</td>
      <td>14</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>47</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>195</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.736198</td>
      <td>1.386294</td>
      <td>8.018625</td>
      <td>6.356108</td>
      <td>1.098612</td>
      <td>1.386294</td>
      <td>5.370638</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0</td>
      <td>74</td>
      <td>5</td>
      <td>1</td>
      <td>30</td>
      <td>5</td>
      <td>0</td>
      <td>118</td>
      <td>17</td>
      <td>48</td>
    </tr>
    <tr>
      <th>196</th>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>7.382746</td>
      <td>2.564949</td>
      <td>0.693147</td>
      <td>2.564949</td>
      <td>2.772589</td>
      <td>0.000000</td>
      <td>...</td>
      <td>1</td>
      <td>25</td>
      <td>0</td>
      <td>0</td>
      <td>138</td>
      <td>0</td>
      <td>0</td>
      <td>68</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>197</th>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>1.945910</td>
      <td>1.386294</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.995732</td>
      <td>1.386294</td>
      <td>1.386294</td>
      <td>0.693147</td>
      <td>...</td>
      <td>4</td>
      <td>40</td>
      <td>17</td>
      <td>2</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>16</td>
      <td>11</td>
    </tr>
    <tr>
      <th>198</th>
      <td>0.000000</td>
      <td>3.135494</td>
      <td>1.945910</td>
      <td>3.135494</td>
      <td>5.318120</td>
      <td>5.036953</td>
      <td>4.394449</td>
      <td>2.944439</td>
      <td>6.232448</td>
      <td>0.000000</td>
      <td>...</td>
      <td>4</td>
      <td>7</td>
      <td>18</td>
      <td>1</td>
      <td>123</td>
      <td>0</td>
      <td>0</td>
      <td>10</td>
      <td>16</td>
      <td>49</td>
    </tr>
    <tr>
      <th>199</th>
      <td>0.693147</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.934474</td>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>...</td>
      <td>7</td>
      <td>72</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>200 rows × 39 columns</p>
</div>




<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>I10</th>
      <th>...</th>
      <th>C18</th>
      <th>C19</th>
      <th>C20</th>
      <th>C21</th>
      <th>C22</th>
      <th>C23</th>
      <th>C24</th>
      <th>C25</th>
      <th>C26</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>1.386294</td>
      <td>5.564520</td>
      <td>0.000000</td>
      <td>9.779567</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>3.526361</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>66</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>96</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000000</td>
      <td>-1.000000</td>
      <td>2.995732</td>
      <td>3.583519</td>
      <td>10.317318</td>
      <td>5.513429</td>
      <td>0.693147</td>
      <td>3.583519</td>
      <td>5.081404</td>
      <td>0.000000</td>
      <td>...</td>
      <td>52</td>
      <td>0</td>
      <td>0</td>
      <td>47</td>
      <td>0</td>
      <td>7</td>
      <td>112</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.098612</td>
      <td>2.564949</td>
      <td>7.607878</td>
      <td>5.105945</td>
      <td>1.945910</td>
      <td>3.583519</td>
      <td>6.261492</td>
      <td>0.000000</td>
      <td>...</td>
      <td>49</td>
      <td>0</td>
      <td>0</td>
      <td>25</td>
      <td>0</td>
      <td>6</td>
      <td>53</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000000</td>
      <td>2.639057</td>
      <td>0.693147</td>
      <td>1.609438</td>
      <td>9.731334</td>
      <td>5.303305</td>
      <td>1.791759</td>
      <td>1.609438</td>
      <td>3.401197</td>
      <td>0.000000</td>
      <td>...</td>
      <td>37</td>
      <td>0</td>
      <td>0</td>
      <td>156</td>
      <td>0</td>
      <td>0</td>
      <td>32</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.653960</td>
      <td>3.332205</td>
      <td>7.596392</td>
      <td>4.962845</td>
      <td>1.609438</td>
      <td>3.496508</td>
      <td>3.637586</td>
      <td>0.000000</td>
      <td>...</td>
      <td>14</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
      <td>1</td>
      <td>47</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>195</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.736198</td>
      <td>1.386294</td>
      <td>8.018625</td>
      <td>6.356108</td>
      <td>1.098612</td>
      <td>1.386294</td>
      <td>5.370638</td>
      <td>0.000000</td>
      <td>...</td>
      <td>74</td>
      <td>5</td>
      <td>1</td>
      <td>30</td>
      <td>5</td>
      <td>0</td>
      <td>118</td>
      <td>17</td>
      <td>48</td>
      <td>0</td>
    </tr>
    <tr>
      <th>196</th>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>0.693147</td>
      <td>7.382746</td>
      <td>2.564949</td>
      <td>0.693147</td>
      <td>2.564949</td>
      <td>2.772589</td>
      <td>0.000000</td>
      <td>...</td>
      <td>25</td>
      <td>0</td>
      <td>0</td>
      <td>138</td>
      <td>0</td>
      <td>0</td>
      <td>68</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>197</th>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>1.945910</td>
      <td>1.386294</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.995732</td>
      <td>1.386294</td>
      <td>1.386294</td>
      <td>0.693147</td>
      <td>...</td>
      <td>40</td>
      <td>17</td>
      <td>2</td>
      <td>41</td>
      <td>0</td>
      <td>0</td>
      <td>12</td>
      <td>16</td>
      <td>11</td>
      <td>1</td>
    </tr>
    <tr>
      <th>198</th>
      <td>0.000000</td>
      <td>3.135494</td>
      <td>1.945910</td>
      <td>3.135494</td>
      <td>5.318120</td>
      <td>5.036953</td>
      <td>4.394449</td>
      <td>2.944439</td>
      <td>6.232448</td>
      <td>0.000000</td>
      <td>...</td>
      <td>7</td>
      <td>18</td>
      <td>1</td>
      <td>123</td>
      <td>0</td>
      <td>0</td>
      <td>10</td>
      <td>16</td>
      <td>49</td>
      <td>0</td>
    </tr>
    <tr>
      <th>199</th>
      <td>0.693147</td>
      <td>-1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.934474</td>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.693147</td>
      <td>...</td>
      <td>72</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>200 rows × 40 columns</p>
</div>




<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 200 entries, 0 to 199
Data columns (total 40 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   I1      200 non-null    float64
 1   I2      200 non-null    float64
 2   I3      200 non-null    float64
 3   I4      200 non-null    float64
 4   I5      200 non-null    float64
 5   I6      200 non-null    float64
 6   I7      200 non-null    float64
 7   I8      200 non-null    float64
 8   I9      200 non-null    float64
 9   I10     200 non-null    float64
 10  I11     200 non-null    float64
 11  I12     200 non-null    float64
 12  I13     200 non-null    float64
 13  C1      200 non-null    int32  
 14  C2      200 non-null    int32  
 15  C3      200 non-null    int32  
 16  C4      200 non-null    int32  
 17  C5      200 non-null    int32  
 18  C6      200 non-null    int32  
 19  C7      200 non-null    int32  
 20  C8      200 non-null    int32  
 21  C9      200 non-null    int32  
 22  C10     200 non-null    int32  
 23  C11     200 non-null    int32  
 24  C12     200 non-null    int32  
 25  C13     200 non-null    int32  
 26  C14     200 non-null    int32  
 27  C15     200 non-null    int32  
 28  C16     200 non-null    int32  
 29  C17     200 non-null    int32  
 30  C18     200 non-null    int32  
 31  C19     200 non-null    int32  
 32  C20     200 non-null    int32  
 33  C21     200 non-null    int32  
 34  C22     200 non-null    int32  
 35  C23     200 non-null    int32  
 36  C24     200 non-null    int32  
 37  C25     200 non-null    int32  
 38  C26     200 non-null    int32  
 39  label   200 non-null    int64  
dtypes: float64(13), int32(26), int64(1)
memory usage: 42.3 KB
</code></pre>
<h3 id="模型部分-1"><a href="#模型部分-1" class="headerlink" title="模型部分"></a>模型部分</h3><h4 id="1-数值型特征的处理"><a href="#1-数值型特征的处理" class="headerlink" title="1.数值型特征的处理"></a>1.数值型特征的处理</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 1-1 数值型特征的输入</span>
dense_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> dense_features<span class="token punctuation">:</span>
    _input <span class="token operator">=</span> Input<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>name<span class="token operator">=</span>f<span class="token punctuation">)</span>
    dense_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>_input<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">dense_inputs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>[&lt;tf.Tensor &#39;I1:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I2:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I3:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I4:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I5:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I6:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I7:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I8:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I9:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I10:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I11:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I12:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;I13:0&#39; shape=(None, 1) dtype=float32&gt;]
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 1-2 数值型特征的拼接</span>
dense_inputs_concat <span class="token operator">=</span> Concatenate<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>dense_inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">dense_inputs_concat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;concatenate_1/concat:0&#39; shape=(None, 13) dtype=float32&gt;
</code></pre>
<h4 id="2-类别型特征的处理"><a href="#2-类别型特征的处理" class="headerlink" title="2.类别型特征的处理"></a>2.类别型特征的处理</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 2-1 类别型特征的输入</span>
sparse_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> f <span class="token keyword">in</span> sparse_features<span class="token punctuation">:</span>
    _input <span class="token operator">=</span> Input<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>name<span class="token operator">=</span>f<span class="token punctuation">)</span>
    sparse_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>_input<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_inputs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>[&lt;tf.Tensor &#39;C1:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C2:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C3:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C4:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C5:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C6:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C7:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C8:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C9:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C10:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C11:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C12:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C13:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C14:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C15:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C16:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C17:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C18:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C19:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C20:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C21:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C22:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C23:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C24:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C25:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;C26:0&#39; shape=(None, 1) dtype=float32&gt;]
</code></pre>
<h5 id="对类别型特征进行Embedding时-分成了两部分"><a href="#对类别型特征进行Embedding时-分成了两部分" class="headerlink" title="对类别型特征进行Embedding时,分成了两部分"></a>对类别型特征进行Embedding时,分成了两部分</h5><ul>
<li>第一部分: wide部分,即将类别型特征Embedding为1维,Falten,与数值型特征进行add()</li>
<li>第二部分: deep部分,Embedding为4维,进行Flaten-&gt;类别型特正concat-&gt;与数值型特征concat-&gt;deep</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 2-2 第一部分</span>
sparse_emb_wide <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span>_input <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sparse_inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    f <span class="token operator">=</span> sparse_features<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    voc_size <span class="token operator">=</span> train_data<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">.</span>nunique<span class="token punctuation">(</span><span class="token punctuation">)</span>
    _emb <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>voc_size<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_input<span class="token punctuation">)</span><span class="token punctuation">)</span>
    sparse_emb_wide<span class="token punctuation">.</span>append<span class="token punctuation">(</span>_emb<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_emb_wide<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>[&lt;tf.Tensor &#39;flatten/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_1/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_2/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_3/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_4/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_5/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_6/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_7/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_8/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_9/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_10/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_11/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_12/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_13/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_14/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_15/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_16/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_17/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_18/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_19/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_20/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_21/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_22/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_23/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_24/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_25/Reshape:0&#39; shape=(None, 1) dtype=float32&gt;]
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_emb_wide_add <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>sparse_emb_wide<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_emb_wide_add<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;add/add_24:0&#39; shape=(None, 1) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 2-2 第二部分</span>
sparse_emb_deep<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span>_input <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sparse_inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    f <span class="token operator">=</span> sparse_features<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    voc_size <span class="token operator">=</span> train_data<span class="token punctuation">[</span>f<span class="token punctuation">]</span><span class="token punctuation">.</span>nunique<span class="token punctuation">(</span><span class="token punctuation">)</span>
    _emb <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>voc_size<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">(</span>_input<span class="token punctuation">)</span><span class="token punctuation">)</span>
    sparse_emb_deep<span class="token punctuation">.</span>append<span class="token punctuation">(</span>_emb<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_emb_deep<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>[&lt;tf.Tensor &#39;flatten_26/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_27/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_28/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_29/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_30/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_31/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_32/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_33/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_34/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_35/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_36/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_37/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_38/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_39/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_40/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_41/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_42/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_43/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_44/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_45/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_46/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_47/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_48/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_49/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_50/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;,
 &lt;tf.Tensor &#39;flatten_51/Reshape:0&#39; shape=(None, 4) dtype=float32&gt;]
</code></pre>
<h4 id="3-该拼接的拼接-该Add-的Add-该deep的deep"><a href="#3-该拼接的拼接-该Add-的Add-该deep的deep" class="headerlink" title="3.该拼接的拼接,该Add()的Add,该deep的deep"></a>3.该拼接的拼接,该Add()的Add,该deep的deep</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 3-1 wide部分</span>

<span class="token comment"># 拼接好的数值型特征dense为1维后与类别型特征进行Add操作</span>
dense_input_concat_dense <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>dense_inputs_concat<span class="token punctuation">)</span>
wide_logits <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>dense_input_concat_dense<span class="token punctuation">,</span>sparse_emb_wide_add<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">wide_logits<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;add_1/add:0&#39; shape=(None, 1) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 3-2 deep部分</span>

<span class="token comment"># 类别型特征的concat->与数值型特征concat->神经网络</span>
sparse_emb_deep_concat <span class="token operator">=</span> Concatenate<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>sparse_emb_deep<span class="token punctuation">)</span>
deep_logit <span class="token operator">=</span> Concatenate<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>sparse_emb_deep_concat<span class="token punctuation">,</span>dense_inputs_concat<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">sparse_emb_deep_concat<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;concatenate_2/concat:0&#39; shape=(None, 104) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">deep_logit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;concatenate_3/concat:0&#39; shape=(None, 117) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"> <span class="token comment"># dnn层，这里的Dropout参数，Dense中的参数及Dense的层数都可以自己设定</span>
dnn_out <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>deep_logit<span class="token punctuation">)</span><span class="token punctuation">)</span>  
dnn_out <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>dnn_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
dnn_out <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>dnn_out<span class="token punctuation">)</span><span class="token punctuation">)</span>

dnn_out <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>dnn_out<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">dnn_out<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;dense_5/BiasAdd:0&#39; shape=(None, 1) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># wide 和deep的拼接</span>
output_logits <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>wide_logits<span class="token punctuation">,</span> dnn_out<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">output_logits<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;add_2/add:0&#39; shape=(None, 1) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">output_layer <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">"sigmoid"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>output_logits<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">output_layer<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>




<pre><code>&lt;tf.Tensor &#39;activation/Sigmoid:0&#39; shape=(None, 1) dtype=float32&gt;
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> Model<span class="token punctuation">(</span>sparse_inputs<span class="token operator">+</span>dense_inputs<span class="token punctuation">,</span> output_layer<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre><code>Model: &quot;functional_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
C1 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C2 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C3 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C4 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C5 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C6 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C7 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C8 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C9 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
C10 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C11 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C12 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C13 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C14 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C15 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C16 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C17 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C18 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C19 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C20 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C21 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C22 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C23 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C24 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C25 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
C26 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 1, 4)         112         C1[0][0]                         
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 1, 4)         372         C2[0][0]                         
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 1, 4)         692         C3[0][0]                         
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 1, 4)         632         C4[0][0]                         
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 1, 4)         52          C5[0][0]                         
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 1, 4)         32          C6[0][0]                         
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 1, 4)         736         C7[0][0]                         
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 1, 4)         80          C8[0][0]                         
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 1, 4)         12          C9[0][0]                         
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 1, 4)         572         C10[0][0]                        
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 1, 4)         696         C11[0][0]                        
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 1, 4)         684         C12[0][0]                        
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 1, 4)         668         C13[0][0]                        
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 1, 4)         60          C14[0][0]                        
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 1, 4)         684         C15[0][0]                        
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 1, 4)         676         C16[0][0]                        
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 1, 4)         40          C17[0][0]                        
__________________________________________________________________________________________________
embedding_43 (Embedding)        (None, 1, 4)         512         C18[0][0]                        
__________________________________________________________________________________________________
embedding_44 (Embedding)        (None, 1, 4)         180         C19[0][0]                        
__________________________________________________________________________________________________
embedding_45 (Embedding)        (None, 1, 4)         20          C20[0][0]                        
__________________________________________________________________________________________________
embedding_46 (Embedding)        (None, 1, 4)         680         C21[0][0]                        
__________________________________________________________________________________________________
embedding_47 (Embedding)        (None, 1, 4)         28          C22[0][0]                        
__________________________________________________________________________________________________
embedding_48 (Embedding)        (None, 1, 4)         44          C23[0][0]                        
__________________________________________________________________________________________________
embedding_49 (Embedding)        (None, 1, 4)         504         C24[0][0]                        
__________________________________________________________________________________________________
embedding_50 (Embedding)        (None, 1, 4)         84          C25[0][0]                        
__________________________________________________________________________________________________
embedding_51 (Embedding)        (None, 1, 4)         364         C26[0][0]                        
__________________________________________________________________________________________________
I1 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I2 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I3 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I4 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I5 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I6 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I7 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I8 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I9 (InputLayer)                 [(None, 1)]          0                                            
__________________________________________________________________________________________________
I10 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
I11 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
I12 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
I13 (InputLayer)                [(None, 1)]          0                                            
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 4)            0           embedding_26[0][0]               
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 4)            0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 4)            0           embedding_28[0][0]               
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 4)            0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 4)            0           embedding_30[0][0]               
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 4)            0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 4)            0           embedding_32[0][0]               
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 4)            0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 4)            0           embedding_34[0][0]               
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 4)            0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 4)            0           embedding_36[0][0]               
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 4)            0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 4)            0           embedding_38[0][0]               
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 4)            0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 4)            0           embedding_40[0][0]               
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 4)            0           embedding_41[0][0]               
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 4)            0           embedding_42[0][0]               
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 4)            0           embedding_43[0][0]               
__________________________________________________________________________________________________
flatten_44 (Flatten)            (None, 4)            0           embedding_44[0][0]               
__________________________________________________________________________________________________
flatten_45 (Flatten)            (None, 4)            0           embedding_45[0][0]               
__________________________________________________________________________________________________
flatten_46 (Flatten)            (None, 4)            0           embedding_46[0][0]               
__________________________________________________________________________________________________
flatten_47 (Flatten)            (None, 4)            0           embedding_47[0][0]               
__________________________________________________________________________________________________
flatten_48 (Flatten)            (None, 4)            0           embedding_48[0][0]               
__________________________________________________________________________________________________
flatten_49 (Flatten)            (None, 4)            0           embedding_49[0][0]               
__________________________________________________________________________________________________
flatten_50 (Flatten)            (None, 4)            0           embedding_50[0][0]               
__________________________________________________________________________________________________
flatten_51 (Flatten)            (None, 4)            0           embedding_51[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 13)           0           I1[0][0]                         
                                                                 I2[0][0]                         
                                                                 I3[0][0]                         
                                                                 I4[0][0]                         
                                                                 I5[0][0]                         
                                                                 I6[0][0]                         
                                                                 I7[0][0]                         
                                                                 I8[0][0]                         
                                                                 I9[0][0]                         
                                                                 I10[0][0]                        
                                                                 I11[0][0]                        
                                                                 I12[0][0]                        
                                                                 I13[0][0]                        
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 104)          0           flatten_26[0][0]                 
                                                                 flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
                                                                 flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
                                                                 flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
                                                                 flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
                                                                 flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
                                                                 flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
                                                                 flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
                                                                 flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
                                                                 flatten_43[0][0]                 
                                                                 flatten_44[0][0]                 
                                                                 flatten_45[0][0]                 
                                                                 flatten_46[0][0]                 
                                                                 flatten_47[0][0]                 
                                                                 flatten_48[0][0]                 
                                                                 flatten_49[0][0]                 
                                                                 flatten_50[0][0]                 
                                                                 flatten_51[0][0]                 
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 117)          0           concatenate_2[0][0]              
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         120832      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           dense_2[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 512)          524800      dropout[0][0]                    
__________________________________________________________________________________________________
embedding (Embedding)           (None, 1, 1)         28          C1[0][0]                         
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 1, 1)         93          C2[0][0]                         
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 1, 1)         173         C3[0][0]                         
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 1, 1)         158         C4[0][0]                         
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 1, 1)         13          C5[0][0]                         
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 1, 1)         8           C6[0][0]                         
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 1, 1)         184         C7[0][0]                         
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 1, 1)         20          C8[0][0]                         
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 1, 1)         3           C9[0][0]                         
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 1, 1)         143         C10[0][0]                        
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 1, 1)         174         C11[0][0]                        
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 1, 1)         171         C12[0][0]                        
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 1, 1)         167         C13[0][0]                        
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 1, 1)         15          C14[0][0]                        
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 1, 1)         171         C15[0][0]                        
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 1, 1)         169         C16[0][0]                        
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 1, 1)         10          C17[0][0]                        
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 1, 1)         128         C18[0][0]                        
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 1, 1)         45          C19[0][0]                        
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 1, 1)         5           C20[0][0]                        
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 1, 1)         170         C21[0][0]                        
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 1, 1)         7           C22[0][0]                        
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 1, 1)         11          C23[0][0]                        
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 1, 1)         126         C24[0][0]                        
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 1, 1)         21          C25[0][0]                        
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 1, 1)         91          C26[0][0]                        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 512)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1)            0           embedding[0][0]                  
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1)            0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 1)            0           embedding_2[0][0]                
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 1)            0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 1)            0           embedding_4[0][0]                
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1)            0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 1)            0           embedding_6[0][0]                
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 1)            0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 1)            0           embedding_8[0][0]                
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 1)            0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 1)            0           embedding_10[0][0]               
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 1)            0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 1)            0           embedding_12[0][0]               
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 1)            0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 1)            0           embedding_14[0][0]               
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 1)            0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 1)            0           embedding_16[0][0]               
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 1)            0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 1)            0           embedding_18[0][0]               
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 1)            0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 1)            0           embedding_20[0][0]               
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 1)            0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 1)            0           embedding_22[0][0]               
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 1)            0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 1)            0           embedding_24[0][0]               
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 1)            0           embedding_25[0][0]               
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            14          concatenate_1[0][0]              
__________________________________________________________________________________________________
add (Add)                       (None, 1)            0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
                                                                 flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
                                                                 flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
                                                                 flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
                                                                 flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
                                                                 flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
                                                                 flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
                                                                 flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
                                                                 flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
                                                                 flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
                                                                 flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
                                                                 flatten_25[0][0]                 
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256)          0           dense_4[0][0]                    
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1)            0           dense_1[0][0]                    
                                                                 add[0][0]                        
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1)            257         dropout_2[0][0]                  
__________________________________________________________________________________________________
add_2 (Add)                     (None, 1)            0           add_1[0][0]                      
                                                                 dense_5[0][0]                    
__________________________________________________________________________________________________
activation (Activation)         (None, 1)            0           add_2[0][0]                      
==================================================================================================
Total params: 788,751
Trainable params: 788,751
Non-trainable params: 0
__________________________________________________________________________________________________
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 显示模型图.这里不放了</span>
<span class="token comment"># from keras.utils import plot_model</span>

<span class="token comment"># plot_model(model, to_file='./WideNDeep_mode_do_it.png', show_shapes=True)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">"adam"</span><span class="token punctuation">,</span> 
                loss<span class="token operator">=</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> 
                metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"binary_crossentropy"</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>AUC<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'auc'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_model_input <span class="token operator">=</span> <span class="token punctuation">&#123;</span>name<span class="token punctuation">:</span> data<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token keyword">for</span> name <span class="token keyword">in</span> dense_features <span class="token operator">+</span> sparse_features<span class="token punctuation">&#125;</span>
    <span class="token comment"># 模型训练</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_model_input<span class="token punctuation">,</span> train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>
            batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>Epoch 1/5
3/3 [==============================] - 1s 487ms/step - loss: 0.8122 - binary_crossentropy: 0.8122 - auc: 0.5660 - val_loss: 1.1823 - val_binary_crossentropy: 1.1823 - val_auc: 0.5840
Epoch 2/5
3/3 [==============================] - 0s 28ms/step - loss: 0.8249 - binary_crossentropy: 0.8249 - auc: 0.5660 - val_loss: 0.6962 - val_binary_crossentropy: 0.6962 - val_auc: 0.5385
Epoch 3/5
3/3 [==============================] - 0s 27ms/step - loss: 0.6133 - binary_crossentropy: 0.6133 - auc: 0.5412 - val_loss: 0.7463 - val_binary_crossentropy: 0.7463 - val_auc: 0.4900
Epoch 4/5
3/3 [==============================] - 0s 25ms/step - loss: 0.6236 - binary_crossentropy: 0.6236 - auc: 0.5601 - val_loss: 0.6182 - val_binary_crossentropy: 0.6182 - val_auc: 0.6054
Epoch 5/5
3/3 [==============================] - 0s 24ms/step - loss: 0.5367 - binary_crossentropy: 0.5367 - auc: 0.6351 - val_loss: 0.7351 - val_binary_crossentropy: 0.7351 - val_auc: 0.7066





&lt;tensorflow.python.keras.callbacks.History at 0x20c5841c400&gt;
</code></pre>
<p>思考题</p>
<ol>
<li>在你的应用场景中，哪些特征适合放在Wide侧，哪些特征适合放在Deep侧，为什么呢？</li>
</ol>
<p>我理解的是具有代表性的特征放在wide部分,具有代表性指的是能直接反馈出用户对物品的喜好的特征,deep部分可以放所有的特征吧<br>2. 为什么Wide部分要用L1 FTRL训练?</p>
<p>采用L1 FTRL是想让Wide部分变得更加稀疏。再白话一点就是，L1 FTRL会让Wide部分的大部分权重都为0，我们准备特征的时候就不用准备那么多0权重的特征了，这大大压缩了模型权重，也压缩了特征向量的维度。<br>3. 为什么Deep部分不特别考虑稀疏性的问题？</p>
<p>Deep部分的输入，要么是Age，App Installs这些数值类特征，要么是已经降维并稠密化的Embedding向量，工程师们不会也不敢把过度稀疏的特征向量直接输入到Deep网络中。所以Deep部分不存在严重的特征稀疏问题，自然可以使用精度更好，更适用于深度学习训练</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">John Doe</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://ddxuexi.github.io/2021/03/18/widendeep-jupyter/">http://ddxuexi.github.io/2021/03/18/widendeep-jupyter/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://ddxuexi.github.io" target="_blank">Hexo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2021/03/18/hello-world/"><img class="prev-cover" src="/" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hello World</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">2</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%83%A8%E5%88%86"><span class="toc-number">1.</span> <span class="toc-text">模型部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%83%A8%E5%88%86-1"><span class="toc-number">2.</span> <span class="toc-text">模型部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E6%95%B0%E5%80%BC%E5%9E%8B%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">1.数值型特征的处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E7%B1%BB%E5%88%AB%E5%9E%8B%E7%89%B9%E5%BE%81%E7%9A%84%E5%A4%84%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">2.类别型特征的处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E7%B1%BB%E5%88%AB%E5%9E%8B%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8CEmbedding%E6%97%B6-%E5%88%86%E6%88%90%E4%BA%86%E4%B8%A4%E9%83%A8%E5%88%86"><span class="toc-number">2.2.1.</span> <span class="toc-text">对类别型特征进行Embedding时,分成了两部分</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%AF%A5%E6%8B%BC%E6%8E%A5%E7%9A%84%E6%8B%BC%E6%8E%A5-%E8%AF%A5Add-%E7%9A%84Add-%E8%AF%A5deep%E7%9A%84deep"><span class="toc-number">2.3.</span> <span class="toc-text">3.该拼接的拼接,该Add()的Add,该deep的deep</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><div class="content"><a class="title" href="/2021/03/18/hello-world/" title="Hello World">Hello World</a><time datetime="2021-03-18T13:32:09.904Z" title="发表于 2021-03-18 21:32:09">2021-03-18</time></div></div><div class="aside-list-item"><div class="content"><a class="title" href="/2021/03/18/widendeep-jupyter/" title="WideNDeep-tf实现">WideNDeep-tf实现</a><time datetime="2021-03-18T08:43:20.095Z" title="发表于 2021-03-18 16:43:20">2021-03-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By John Doe</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>